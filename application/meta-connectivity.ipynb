{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to do meta-connectivity in two parts. First part: Homotopic connectivity analysis. Second part: cluster analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The homotopic connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "from turtle import color\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/mnt/c/Users/Wayne/tvb/Network-science-Toolbox/Python')\n",
    "# sys.path.append('/home/wayne/github/TVB_workflow/new_g_optimal')\n",
    "# sys.path.append('/home/wayne/github/Network-science-Toolbox/Python')\n",
    "from TS2dFCstream import TS2dFCstream\n",
    "from dFCstream2Trimers import dFCstream2Trimers\n",
    "from dFCstream2MC import dFCstream2MC\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats.stats import pearsonr\n",
    "import itertools\n",
    "import os\n",
    "import scipy.io\n",
    "\n",
    "\"\"\"\n",
    "@Author: Yile Wang\n",
    "\n",
    "This script is used to calculate the homotopic meta-connectivity in four groups, SNC, NC, MCI, AD\n",
    "\"\"\"\n",
    "\n",
    "# brain region labels for your reference\n",
    "regions = ['aCNG-L', 'aCNG-R','mCNG-L','mCNG-R','pCNG-L','pCNG-R', 'HIP-L','HIP-R','PHG-L','PHG-R','AMY-L','AMY-R', 'sTEMp-L','sTEMP-R','mTEMp-L','mTEMp-R']\n",
    "regionswithgroups = ['groups','aCNG-L', 'aCNG-R','mCNG-L','mCNG-R','pCNG-L','pCNG-R', 'HIP-L','HIP-R','PHG-L','PHG-R','AMY-L','AMY-R', 'sTEMp-L','sTEMP-R','mTEMp-L','mTEMp-R']\n",
    "group = ['SNC', 'NC', 'MCI','AD']\n",
    "regionsHalf = np.array(['aCNG', 'mCNG','pCNG','HIP','PHG','AMY','sTEMp', 'mTEMp'])\n",
    "\n",
    "regions14 = []\n",
    "for i in range(14):\n",
    "    wt = [\"regions_\", str(i)]\n",
    "    wt = \"\".join(wt)\n",
    "    regions14.append(wt)\n",
    "\n",
    "# iterate simulated functional connectivity\n",
    "if __name__ == \"__main__\":\n",
    "    Trimer_Homo = pd.DataFrame(columns=['groups','trimer_homo','aCNG','mCNG','pCNG','HIP','PHG','AMY','sTEMp','mTEMp' ])\n",
    "    Trimer_Hetero  = pd.DataFrame(columns=['groups','trimer_hetero','aCNG','mCNG','pCNG','HIP','PHG','AMY','sTEMp','mTEMp' ])\n",
    "    Trimer = pd.DataFrame()\n",
    "    \n",
    "    for grp in group:\n",
    "        # subject case ids\n",
    "        ldir = os.listdir(\"/mnt/c/Users/Wayne/tvb/TS-4-Vik/\"+ grp+'-TS')\n",
    "        # ldir = os.listdir('/home/wayne/TS-4-Vik/'+grp+'-TS/')\n",
    "        MC_all = np.zeros((16,16, 16, len(ldir)))\n",
    "        tmp_homo = np.array([])\n",
    "        homoRegions = np.ones((1,len(regionsHalf)))\n",
    "        for ind, y in enumerate(ldir):\n",
    "            # import empirical functional connectivity\n",
    "            # Here is the path of the mat file of the FC data\n",
    "            pth_efc = \"/mnt/c/Users/Wayne/tvb/TS-4-Vik/\"+ grp+'-TS/'+ y +\"/ROISignals_\"+ y +\".mat\"\n",
    "            # pth_efc = \"/home/wayne/TS-4-Vik/\"+grp+\"-TS/\"+ y +\"/ROISignals_\"+ y +\".mat\"\n",
    "            ea = scipy.io.loadmat(pth_efc)\n",
    "            all = ea['ROISignals']\n",
    "            df = pd.DataFrame.from_dict(all)\n",
    "            df.columns = regions\n",
    "            # calculate the meta-connectivity, using existing script:\n",
    "            dFCstream = TS2dFCstream(df.to_numpy(), 5, None, '2D')\n",
    "            # Calculate MC\n",
    "            MC_MC = dFCstream2MC(dFCstream)\n",
    "            # Calculate Trimers results, with nxnxn information\n",
    "            MC_all[:,:,:,ind] = dFCstream2Trimers(dFCstream)\n",
    "        MC_homo = np.mean(MC_all, 3)\n",
    "        MC_single_groups = np.zeros((14, 8))\n",
    "        # only pick up L sides of the regions\n",
    "        for idnx, i in enumerate(range(0,15,2)):\n",
    "            j = i+1 # represent R side\n",
    "            newList = list(range(16))\n",
    "            del newList[i:j+1] # drop the target regions L and R\n",
    "            for idx, restNode in enumerate(newList):\n",
    "                MC_single_groups[idx,idnx] = MC_homo[i,j,restNode] # In rest of the 14 regions, iternate the third dimensions, and pick up the homotopic MC\n",
    "        MC_single = pd.DataFrame(MC_single_groups, index=regions14, columns=regionsHalf)\n",
    "        grpInfo = [grp] * 14\n",
    "        MC_single.insert(0, \"group\", grpInfo)\n",
    "        Trimer = Trimer.append(MC_single)\n",
    "    # Trimer.to_excel(\"/mnt/c/Users/Wayne/tvb/gc1sec_res/mc_homo.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 1, data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "from turtle import color\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/mnt/c/Users/Wayne/tvb/Network-science-Toolbox/Python')\n",
    "# sys.path.append('/home/wayne/github/TVB_workflow/new_g_optimal')\n",
    "# sys.path.append('/home/wayne/github/Network-science-Toolbox/Python')\n",
    "from TS2dFCstream import TS2dFCstream\n",
    "from dFCstream2Trimers import dFCstream2Trimers\n",
    "from dFCstream2MC import dFCstream2MC\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats.stats import pearsonr\n",
    "import itertools\n",
    "import os\n",
    "import scipy.io\n",
    "\n",
    "# label = '/mnt/c/Users/Wayne/tvb/gc1sec_res/meta/Region_Labels_90ROIs.txt'\n",
    "# list_ = open(label).read().split()\n",
    "# region = list_[1::2]\n",
    "\n",
    "regions = ['aCNG-L', 'aCNG-R','mCNG-L','mCNG-R','pCNG-L','pCNG-R', 'HIP-L','HIP-R','PHG-L','PHG-R','AMY-L','AMY-R', 'sTEMp-L','sTEMP-R','mTEMp-L','mTEMp-R']\n",
    "\n",
    "group = ['SNC', 'NC', 'MCI','AD']\n",
    "path = '/mnt/c/Users/Wayne/tvb/stat_data/Gc_Go.xlsx'\n",
    "coData = pd.read_excel(path, index_col=0)\n",
    "\n",
    "\n",
    "edge_num = int((len(regions)*(len(regions)-1)) / 2)\n",
    "mc_all = np.zeros((edge_num,edge_num, len(group)))\n",
    "for id, grp in enumerate(group):\n",
    "    _mc = np.zeros((edge_num,edge_num, len(coData.index[coData.groups == grp])))\n",
    "    for ind, y in enumerate(coData.index[coData.groups == grp]):\n",
    "        # import empirical functional connectivity\n",
    "        # Here is the path of the mat file of the FC data\n",
    "        try:\n",
    "            ldir = \"/mnt/c/Users/Wayne/tvb/TS-4-Vik/\"+ grp+'-TS/'+ y +\"/ROISignals_\"+ y +\".mat\"\n",
    "            ea = scipy.io.loadmat(ldir)\n",
    "            all = ea['ROISignals']\n",
    "            df = pd.DataFrame.from_dict(all)\n",
    "            df.columns = regions\n",
    "            dFCstream = TS2dFCstream(df.to_numpy(), 5, None, '2D')\n",
    "            # Calculate MC & write to matrix\n",
    "            _mc[:,:,ind] = dFCstream2MC(dFCstream)\n",
    "        except:\n",
    "            continue\n",
    "    mc_all[:,:,id] = np.mean(_mc, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 2, louvain algorithm for community check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the cluster\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import os\n",
    "import pandas as pd\n",
    "from bct.algorithms import community_louvain\n",
    "from bct.algorithms.centrality import participation_coef_sign\n",
    "\n",
    "group = ['SNC', 'NC', 'MCI','AD']\n",
    "regions = ['aCNG-L', 'aCNG-R','mCNG-L','mCNG-R','pCNG-L','pCNG-R', 'HIP-L','HIP-R','PHG-L','PHG-R','AMY-L','AMY-R', 'sTEMp-L','sTEMP-R','mTEMp-L','mTEMp-R']\n",
    "node_dict = {0:'aCNG-L', 1:'aCNG-R',2: 'mCNG-L',3:'mCNG-R',4:'pCNG-L',5:'pCNG-R', 6:'HIP-L',7:'HIP-R',8:'PHG-L',9:'PHG-R',10:'AMY-L',11:'AMY-R', 12:'sTEMp-L',13:'sTEMp-R',14:'mTEMp-L',15:'mTEMp-R'}\n",
    "\n",
    "# combination set\n",
    "comba = list(itertools.combinations(range(len(regions)), 2))\n",
    "# give labels to comba\n",
    "comba_with_name = []\n",
    "for x in comba:\n",
    "    tmp_one = (regions[x[0]], regions[x[1]])\n",
    "    comba_with_name.append(tmp_one)\n",
    "\n",
    "def mat_preprocessing(mat, group_index, labels):\n",
    "    mat = pd.DataFrame(mat[:,:,group_index], columns=labels, index=labels)\n",
    "    return mat\n",
    "\n",
    "def links_single_module(ci, cluster_index):\n",
    "    #bctpy\n",
    "    links_within_m = [item for item in np.where(ci==cluster_index)[0]]\n",
    "    return links_within_m\n",
    "\n",
    "def participation_coef_single_cluster(mat, links_within_m):\n",
    "    participation_coef_single = []\n",
    "    for i in range(len(links_within_m)):\n",
    "        drop_links_within = [ele for ele in links_within_m if ele not in [i]]\n",
    "        drop_links_outside = [ele for ele in range(len(mat.index)) if ele not in [i]]\n",
    "        n_l = np.sum(mat.iloc[drop_links_outside, links_within_m[i]])\n",
    "        single_link = []\n",
    "        for j in range(len(drop_links_within)):\n",
    "            n_l_within_m = np.sum(mat.iloc[drop_links_within[j], links_within_m[i]])\n",
    "            _value = (n_l_within_m/n_l)**2\n",
    "            single_link.append(_value)\n",
    "        pl=1 - np.sum(single_link)\n",
    "        participation_coef_single.append(pl)\n",
    "    return participation_coef_single\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "overall_df = pd.DataFrame()\n",
    "for ind in range(len(group)):\n",
    "    mat = mat_preprocessing(mc_all, ind, labels=comba_with_name)\n",
    "    ci, Q = community_louvain(mat.to_numpy(), gamma=1.1, B='negative_asym', seed=None)\n",
    "    # fisrt method:\n",
    "    pos,_ = participation_coef_sign(mat.to_numpy(), ci)\n",
    "    cluster_info = pd.DataFrame(ci)\n",
    "    cluster_info.columns = [\"cluster\"]\n",
    "    part_coe = pd.DataFrame(pos)\n",
    "    part_coe.columns = [\"participation_coef\"]\n",
    "    grp_info = pd.Series([group[ind]])\n",
    "    grp_col = grp_info.repeat(len(mat.index))\n",
    "    grp_col = grp_col.reset_index(drop=True)\n",
    "    _tmp = pd.concat([grp_col, part_coe, cluster_info],axis=1, ignore_index=True)\n",
    "    overall_df = pd.concat([overall_df, _tmp], ignore_index=True)\n",
    "overall_df.columns = [[\"group\",\"participation_coef\", \"cluster\"]]\n",
    "print(overall_df)\n",
    "overall_df.to_excel(\"/mnt/c/Users/Wayne/tvb/gc1sec_res/meta/paricipation_coef.xlsx\")\n",
    "\n",
    "    #second method:\n",
    "#     single_grp_all_clusters = {}\n",
    "#     for cii in range(1,max(ci)+1):\n",
    "#         links_within_m = links_single_module(ci, cii)\n",
    "#         participation_coef_single = participation_coef_single_cluster(mat, links_within_m)\n",
    "#         str_name = \"cluster_\"+str(cii)\n",
    "#         single_grp_all_clusters[str_name] = participation_coef_single\n",
    "#     keys_list = list(single_grp_all_clusters.keys())\n",
    "\n",
    "\n",
    "#     all_clusters_df = pd.DataFrame()\n",
    "#     for ii in range(len(keys_list)):\n",
    "#         _tmp = pd.DataFrame({keys_list[ii]:single_grp_all_clusters[keys_list[ii]]})\n",
    "#         _tmp.columns = [\"participation_coef\"]\n",
    "#         cluster_info = pd.Series([keys_list[ii]])\n",
    "#         cluster_col = cluster_info.repeat(len(_tmp))\n",
    "#         cluster_col = cluster_col.reset_index(drop=True)\n",
    "#         _tmp_grp = pd.concat([_tmp, cluster_col], axis=1, ignore_index=True)\n",
    "#         all_clusters_df = pd.concat([all_clusters_df,_tmp_grp], ignore_index=True)\n",
    "\n",
    "#     grp_info = pd.Series([group[ind]])\n",
    "#     grp_col = grp_info.repeat(len(mat.index))\n",
    "#     grp_col = grp_col.reset_index(drop=True)\n",
    "#     all_clusters_df = pd.concat([grp_col,all_clusters_df], axis=1, ignore_index=True)\n",
    "#     all_clusters_df.columns = [\"group\",\"participation_coef\", \"cluster\"]\n",
    "#     overall_df = pd.concat([overall_df, all_clusters_df], ignore_index=True)\n",
    "# overall_df.to_excel(\"/mnt/c/Users/Wayne/tvb/gc1sec_res/meta/paricipation_coef.xlsx\")\n",
    "\n",
    "\n",
    "# ### create edge network\n",
    "# G = nx.Graph()\n",
    "# G.add_edges_from(edge)\n",
    "\n",
    "# ### retrun partition as a dict\n",
    "# partition = community_louvain.best_partition(G)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tvbenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3c26eedd07840027ff202a94d88c89e67a86d8b5dcd58f087e1d46a589dbbcf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
