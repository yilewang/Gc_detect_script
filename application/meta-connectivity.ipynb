{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to do meta-connectivity in two parts. First part: Homotopic connectivity analysis. Second part: cluster analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The homotopic connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "from turtle import color\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/mnt/c/Users/Wayne/tvb/Network-science-Toolbox/Python')\n",
    "# sys.path.append('/home/wayne/github/TVB_workflow/new_g_optimal')\n",
    "# sys.path.append('/home/wayne/github/Network-science-Toolbox/Python')\n",
    "from TS2dFCstream import TS2dFCstream\n",
    "from dFCstream2Trimers import dFCstream2Trimers\n",
    "from dFCstream2MC import dFCstream2MC\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats.stats import pearsonr\n",
    "import itertools\n",
    "import os\n",
    "import scipy.io\n",
    "\n",
    "plat4 = \"desktop\"\n",
    "\n",
    "\"\"\"\n",
    "@Author: Yile Wang\n",
    "\n",
    "This script is used to calculate the homotopic meta-connectivity in four groups, SNC, NC, MCI, AD\n",
    "\"\"\"\n",
    "\n",
    "# brain region labels for your reference\n",
    "regions = ['aCNG-L', 'aCNG-R','mCNG-L','mCNG-R','pCNG-L','pCNG-R', 'HIP-L','HIP-R','PHG-L','PHG-R','AMY-L','AMY-R', 'sTEMp-L','sTEMP-R','mTEMp-L','mTEMp-R']\n",
    "regionswithgroups = ['groups','aCNG-L', 'aCNG-R','mCNG-L','mCNG-R','pCNG-L','pCNG-R', 'HIP-L','HIP-R','PHG-L','PHG-R','AMY-L','AMY-R', 'sTEMp-L','sTEMP-R','mTEMp-L','mTEMp-R']\n",
    "group = ['SNC', 'NC', 'MCI','AD']\n",
    "regionsHalf = np.array(['aCNG', 'mCNG','pCNG','HIP','PHG','AMY','sTEMp', 'mTEMp'])\n",
    "\n",
    "regions14 = []\n",
    "for i in range(14):\n",
    "    wt = [\"regions_\", str(i)]\n",
    "    wt = \"\".join(wt)\n",
    "    regions14.append(wt)\n",
    "\n",
    "# iterate simulated functional connectivity\n",
    "if __name__ == \"__main__\":\n",
    "    Trimer_Homo = pd.DataFrame(columns=['groups','trimer_homo','aCNG','mCNG','pCNG','HIP','PHG','AMY','sTEMp','mTEMp' ])\n",
    "    Trimer_Hetero  = pd.DataFrame(columns=['groups','trimer_hetero','aCNG','mCNG','pCNG','HIP','PHG','AMY','sTEMp','mTEMp' ])\n",
    "    Trimer = pd.DataFrame()\n",
    "    \n",
    "    for grp in group:\n",
    "        # subject case ids\n",
    "        if plat4 == \"desktop\":\n",
    "            ldir = os.listdir(\"/mnt/c/Users/Wayne/tvb/TS-4-Vik/\"+ grp+'-TS')\n",
    "        elif plat4 == \"laptop\":\n",
    "            ldir = os.listdir(\"/home/yat-lok/workspace/data4project/lateralization/ts_fmri/\"+ grp+'-TS')\n",
    "        # ldir = os.listdir('/home/wayne/TS-4-Vik/'+grp+'-TS/')\n",
    "        MC_all = np.zeros((16,16, 16, len(ldir)))\n",
    "        tmp_homo = np.array([])\n",
    "        homoRegions = np.ones((1,len(regionsHalf)))\n",
    "        for ind, y in enumerate(ldir):\n",
    "            # import empirical functional connectivity\n",
    "            # Here is the path of the mat file of the FC data\n",
    "            if plat4 == \"desktop\":\n",
    "                pth_efc = \"/mnt/c/Users/Wayne/tvb/TS-4-Vik/\"+ grp+'-TS/'+ y +\"/ROISignals_\"+ y +\".mat\"\n",
    "            elif plat4 == \"laptop\":\n",
    "                pth_efc = \"/home/yat-lok/workspace/data4project/lateralization/ts_fmri/\"+ grp+'-TS/'+ y +\"/ROISignals_\"+ y +\".mat\"\n",
    "            # pth_efc = \"/home/wayne/TS-4-Vik/\"+grp+\"-TS/\"+ y +\"/ROISignals_\"+ y +\".mat\"\n",
    "            ea = scipy.io.loadmat(pth_efc)\n",
    "            all = ea['ROISignals']\n",
    "            df = pd.DataFrame.from_dict(all)\n",
    "            df.columns = regions\n",
    "            # calculate the meta-connectivity, using existing script:\n",
    "            dFCstream = TS2dFCstream(df.to_numpy(), 5, None, '2D')\n",
    "            # Calculate MC\n",
    "            MC_MC = dFCstream2MC(dFCstream)\n",
    "            # Calculate Trimers results, with nxnxn information\n",
    "            MC_all[:,:,:,ind] = dFCstream2Trimers(dFCstream)\n",
    "        MC_homo = np.mean(MC_all, 3)\n",
    "        MC_single_groups = np.zeros((14, 8))\n",
    "        # only pick up L sides of the regions\n",
    "        for idnx, i in enumerate(range(0,15,2)):\n",
    "            j = i+1 # represent R side\n",
    "            newList = list(range(16))\n",
    "            del newList[i:j+1] # drop the target regions L and R\n",
    "            for idx, restNode in enumerate(newList):\n",
    "                MC_single_groups[idx,idnx] = MC_homo[i,j,restNode] # In rest of the 14 regions, iternate the third dimensions, and pick up the homotopic MC\n",
    "        MC_single = pd.DataFrame(MC_single_groups, index=regions14, columns=regionsHalf)\n",
    "        grpInfo = [grp] * 14\n",
    "        MC_single.insert(0, \"group\", grpInfo)\n",
    "        Trimer = Trimer.append(MC_single)\n",
    "    # Trimer.to_excel(\"/mnt/c/Users/Wayne/tvb/gc1sec_res/mc_homo.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 1, data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "from turtle import color\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/home/yat-lok/workspace/Network-science-Toolbox/Python')\n",
    "# sys.path.append('/home/wayne/github/TVB_workflow/new_g_optimal')\n",
    "# sys.path.append('/home/wayne/github/Network-science-Toolbox/Python')\n",
    "from TS2dFCstream import TS2dFCstream\n",
    "from dFCstream2Trimers import dFCstream2Trimers\n",
    "from dFCstream2MC import dFCstream2MC\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats.stats import pearsonr\n",
    "import itertools\n",
    "import os\n",
    "import scipy.io\n",
    "\n",
    "# label = '/mnt/c/Users/Wayne/tvb/gc1sec_res/meta/Region_Labels_90ROIs.txt'\n",
    "# list_ = open(label).read().split()\n",
    "# region = list_[1::2]\n",
    "\n",
    "regions = ['aCNG-L', 'aCNG-R','mCNG-L','mCNG-R','pCNG-L','pCNG-R', 'HIP-L','HIP-R','PHG-L','PHG-R','AMY-L','AMY-R', 'sTEMp-L','sTEMP-R','mTEMp-L','mTEMp-R']\n",
    "group = ['SNC', 'NC', 'MCI','AD']\n",
    "# path = '/mnt/c/Users/Wayne/tvb/stat_data/Gc_Go.xlsx'\n",
    "\n",
    "# combination set\n",
    "comba = list(itertools.combinations(range(len(regions)), 2))\n",
    "# give labels to comba\n",
    "comba_with_name = []\n",
    "for x in comba:\n",
    "    tmp_one = (regions[x[0]], regions[x[1]])\n",
    "    comba_with_name.append(tmp_one)\n",
    "\n",
    "\n",
    "path = '/home/yat-lok/workspace/data4project/lateralization/tvb_parameters.xlsx'\n",
    "coData = pd.read_excel(path, index_col=0)\n",
    "\n",
    "djouya_index = scipy.io.loadmat('/home/yat-lok/workspace/data4project/lateralization/gc1sec_res/meta/idx.mat')\n",
    "mc_index = djouya_index['idx'].T[0] -1\n",
    "\n",
    "module_ci = []\n",
    "for i in range(120):\n",
    "    if i < 20:\n",
    "        module_ci.append(1)\n",
    "    elif i >=20 and i < 40:\n",
    "        module_ci.append(2)\n",
    "    elif i >=40 and i < 60:\n",
    "        module_ci.append(3)\n",
    "    elif i >= 60 and i < 75:\n",
    "        module_ci.append(4)\n",
    "    else:\n",
    "        module_ci.append(5)\n",
    "\n",
    "\n",
    "edge_num = int((len(regions)*(len(regions)-1)) / 2)\n",
    "mc_all = np.zeros((edge_num,edge_num, len(group)))\n",
    "for id, grp in enumerate(group):\n",
    "    mc_subject = np.zeros((edge_num,edge_num, len(coData.index[coData.groups == grp])))\n",
    "    for ind, y in enumerate(coData.index[coData.groups == grp]):\n",
    "        # import empirical functional connectivity\n",
    "        # Here is the path of the mat file of the FC data\n",
    "        # ldir = \"/mnt/c/Users/Wayne/tvb/TS-4-Vik/\"+ grp+'-TS/'+ y +\"/ROISignals_\"+ y +\".mat\"\n",
    "        ldir = \"/home/yat-lok/workspace/data4project/lateralization/ts_fmri/\"+ grp+'-TS/'+ y +\"/ROISignals_\"+ y +\".mat\"\n",
    "        ea = scipy.io.loadmat(ldir)\n",
    "        all = ea['ROISignals']\n",
    "        df = pd.DataFrame.from_dict(all)\n",
    "        df.columns = regions\n",
    "        dFCstream = TS2dFCstream(df.to_numpy(), 5, None, '2D')\n",
    "        _mc = dFCstream2MC(dFCstream)\n",
    "        # sort the matrix\n",
    "        mc_single = np.zeros((len(mc_index),len(mc_index)))\n",
    "        for mc_row in range(len(mc_index)-1):\n",
    "            for mc_col in range(mc_row+1,len(mc_index)):\n",
    "                mc_single[mc_row, mc_col] = _mc[mc_index[mc_row], mc_index[mc_col]]\n",
    "        mc_sorted_single = mc_single + mc_single.T\n",
    "        # ci, Q = community_louvain(mc_sorted_single, gamma=1.1, ci=module_ci, B='negative_asym', seed=None)\n",
    "        # pos,_ = participation_coef_sign(mc_sorted_single, module_ci)\n",
    "        # mc_single = np.zeros((len(mc_index),len(mc_index)))\n",
    "        # for mc_row in range(len(mc_index)-1):\n",
    "        #     for mc_col in range(mc_row+1,len(mc_index)):\n",
    "        #         mc_single[mc_row, mc_col] = _mc[ci[mc_row], ci[mc_col]]\n",
    "        # mc_sorted_single = mc_single + mc_single.T\n",
    "        # Calculate MC & write to matrix\n",
    "        mc_subject[:,:,ind] = mc_sorted_single\n",
    "    mc_all[:,:,id] = np.mean(mc_subject, axis=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 2, louvain algorithm for community check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the cluster\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import os\n",
    "import pandas as pd\n",
    "from bct.algorithms import community_louvain\n",
    "from bct.algorithms.centrality import participation_coef_sign\n",
    "\n",
    "group = ['SNC', 'NC', 'MCI','AD']\n",
    "regions = ['aCNG-L', 'aCNG-R','mCNG-L','mCNG-R','pCNG-L','pCNG-R', 'HIP-L','HIP-R','PHG-L','PHG-R','AMY-L','AMY-R', 'sTEMp-L','sTEMP-R','mTEMp-L','mTEMp-R']\n",
    "node_dict = {0:'aCNG-L', 1:'aCNG-R',2: 'mCNG-L',3:'mCNG-R',4:'pCNG-L',5:'pCNG-R', 6:'HIP-L',7:'HIP-R',8:'PHG-L',9:'PHG-R',10:'AMY-L',11:'AMY-R', 12:'sTEMp-L',13:'sTEMp-R',14:'mTEMp-L',15:'mTEMp-R'}\n",
    "\n",
    "\n",
    "\n",
    "def mat_preprocessing(mat, group_index, labels):\n",
    "    mat = pd.DataFrame(mat[:,:,group_index], columns=labels, index=labels)\n",
    "    return mat\n",
    "\n",
    "\n",
    "overall_df = pd.DataFrame()\n",
    "for ind in range(len(group)):\n",
    "    mat = mat_preprocessing(mc_all, ind, labels=np.array(comba_with_name)[mc_index])\n",
    "    ci, Q = community_louvain(mat.to_numpy(), ci=module_ci, gamma = 1.5, B='negative_asym', seed=None)\n",
    "    # fisrt method:\n",
    "    pos,_ = participation_coef_sign(mat.to_numpy(), module_ci)\n",
    "    ci_name_list = [\"cluster_\" + str(i) for i in module_ci]\n",
    "    cluster_info = pd.DataFrame(ci_name_list)\n",
    "    cluster_info.columns = [\"cluster\"]\n",
    "    part_coe = pd.DataFrame(pos)\n",
    "    part_coe.columns = [\"participation_coef\"]\n",
    "    grp_info = pd.Series([group[ind]])\n",
    "    grp_col = grp_info.repeat(len(mat.index))\n",
    "    grp_col = grp_col.reset_index(drop=True)\n",
    "    _tmp = pd.concat([grp_col, part_coe, cluster_info],axis=1, ignore_index=True)\n",
    "    overall_df = pd.concat([overall_df, _tmp], ignore_index=True)\n",
    "overall_df.columns = [\"group\",\"participation_coef\", \"cluster\"]\n",
    "overall_df.to_excel(\"/home/yat-lok/workspace/data4project/lateralization/gc1sec_res/meta/participation_coef.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def links_single_module(ci, cluster_index):\n",
    "#     #bctpy\n",
    "#     links_within_m = [item for item in np.where(ci==cluster_index)[0]]\n",
    "#     return links_within_m\n",
    "\n",
    "# def participation_coef_single_cluster(mat, links_within_m):\n",
    "#     participation_coef_single = []\n",
    "#     for i in range(len(links_within_m)):\n",
    "#         drop_links_within = [ele for ele in links_within_m if ele not in [i]]\n",
    "#         drop_links_outside = [ele for ele in range(len(mat.index)) if ele not in [i]]\n",
    "#         n_l = np.sum(mat.iloc[drop_links_outside, links_within_m[i]])\n",
    "#         single_link = []\n",
    "#         for j in range(len(drop_links_within)):\n",
    "#             n_l_within_m = np.sum(mat.iloc[drop_links_within[j], links_within_m[i]])\n",
    "#             _value = (n_l_within_m/n_l)**2\n",
    "#             single_link.append(_value)\n",
    "#         pl=1 - np.sum(single_link)\n",
    "#         participation_coef_single.append(pl)\n",
    "#     return participation_coef_single\n",
    "\n",
    "# second method:\n",
    "#     single_grp_all_clusters = {}\n",
    "#     for cii in range(1,max(ci)+1):\n",
    "#         links_within_m = links_single_module(ci, cii)\n",
    "#         participation_coef_single = participation_coef_single_cluster(mat, links_within_m)\n",
    "#         str_name = \"cluster_\"+str(cii)\n",
    "#         single_grp_all_clusters[str_name] = participation_coef_single\n",
    "#     keys_list = list(single_grp_all_clusters.keys())\n",
    "\n",
    "\n",
    "#     all_clusters_df = pd.DataFrame()\n",
    "#     for ii in range(len(keys_list)):\n",
    "#         _tmp = pd.DataFrame({keys_list[ii]:single_grp_all_clusters[keys_list[ii]]})\n",
    "#         _tmp.columns = [\"participation_coef\"]\n",
    "#         cluster_info = pd.Series([keys_list[ii]])\n",
    "#         cluster_col = cluster_info.repeat(len(_tmp))\n",
    "#         cluster_col = cluster_col.reset_index(drop=True)\n",
    "#         _tmp_grp = pd.concat([_tmp, cluster_col], axis=1, ignore_index=True)\n",
    "#         all_clusters_df = pd.concat([all_clusters_df,_tmp_grp], ignore_index=True)\n",
    "\n",
    "#     grp_info = pd.Series([group[ind]])\n",
    "#     grp_col = grp_info.repeat(len(mat.index))\n",
    "#     grp_col = grp_col.reset_index(drop=True)\n",
    "#     all_clusters_df = pd.concat([grp_col,all_clusters_df], axis=1, ignore_index=True)\n",
    "#     all_clusters_df.columns = [\"group\",\"participation_coef\", \"cluster\"]\n",
    "#     overall_df = pd.concat([overall_df, all_clusters_df], ignore_index=True)\n",
    "# overall_df.to_excel(\"/mnt/c/Users/Wayne/tvb/gc1sec_res/meta/participation_coef.xlsx\")\n",
    "\n",
    "\n",
    "# ### create edge network\n",
    "# G = nx.Graph()\n",
    "# G.add_edges_from(edge)\n",
    "\n",
    "# ### retrun partition as a dict\n",
    "# partition = community_louvain.best_partition(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ci, Q = community_louvain(mc_all[:,:,1], gamma=1.1, ci=module_ci, B='negative_asym', seed=None)\n",
    "# mc_plot=np.zeros((120,120))\n",
    "# for mc_row in range(120-1):\n",
    "#     for mc_col in range(mc_row+1,120):\n",
    "#         mc_plot[mc_row, mc_col] = mc_all[:,:,1][ci[mc_row], ci[mc_col]]\n",
    "# mc_sorted_single = mc_single + mc_single.T\n",
    "\n",
    "\n",
    "fig=plt.figure(figsize=(7,5), dpi=300)\n",
    "axes = fig.add_subplot(111)\n",
    "sns.heatmap(mc_all[:,:,1],cmap=\"crest_r\", ax=axes)\n",
    "axes.set_ylabel(\"edges\")\n",
    "axes.set_xlabel(\"edges\")\n",
    "axes.set_yticks(np.arange(0,121,20))\n",
    "axes.set_xticks(np.arange(0,121,20))\n",
    "axes.set_yticklabels(np.arange(0,121,20))\n",
    "axes.set_xticklabels(np.arange(0,121,20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An individualized method of meta-connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homotopic connectivity MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   group caseid      aCNG      mCNG      pCNG       HIP       PHG       AMY  \\\n",
      "0    SNC  4073A  0.712205  0.812818  0.782347  0.734770  0.743284  0.655958   \n",
      "1    SNC  2820A  0.422224  0.747399  0.770929  0.621996  0.716453  0.463765   \n",
      "2    SNC  8709A  0.789380  0.718027  0.678447  0.618535  0.664798  0.430175   \n",
      "3    SNC  3358A  0.770221  0.538870  0.710808  0.758512  0.693780  0.668941   \n",
      "4    SNC  5184A  0.653113  0.793308  0.793245  0.411089  0.450543  0.589724   \n",
      "..   ...    ...       ...       ...       ...       ...       ...       ...   \n",
      "69    AD  0306A  0.578440  0.642297  0.317123  0.641448  0.561290  0.274161   \n",
      "70    AD  5368A  0.769050  0.785401  0.531676  0.640481  0.780393  0.519834   \n",
      "71    AD  0506A  0.880454  0.800061  0.525922  0.770302  0.614247  0.562948   \n",
      "72    AD  1477A  0.764230  0.781820  0.574817  0.783895  0.727518  0.753258   \n",
      "73    AD  3255A  0.839644  0.446687  0.616240 -0.387720 -0.077344 -0.144543   \n",
      "\n",
      "       sTEMp     mTEMp  \n",
      "0   0.580636  0.576558  \n",
      "1   0.778032  0.749472  \n",
      "2   0.471963  0.702860  \n",
      "3   0.711260  0.757448  \n",
      "4   0.721396  0.735096  \n",
      "..       ...       ...  \n",
      "69  0.315294  0.289498  \n",
      "70  0.649646  0.773270  \n",
      "71  0.749071  0.420248  \n",
      "72  0.734033  0.609474  \n",
      "73 -0.437998 -0.186525  \n",
      "\n",
      "[74 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from turtle import color\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/home/yat-lok/workspace/Network-science-Toolbox/Python')\n",
    "# sys.path.append('/home/wayne/github/TVB_workflow/new_g_optimal')\n",
    "# sys.path.append('/home/wayne/github/Network-science-Toolbox/Python')\n",
    "from TS2dFCstream import TS2dFCstream\n",
    "from dFCstream2Trimers import dFCstream2Trimers\n",
    "from dFCstream2MC import dFCstream2MC\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats.stats import pearsonr\n",
    "import itertools\n",
    "import os\n",
    "import scipy.io\n",
    "\n",
    "\"\"\"\n",
    "@Author: Yile Wang\n",
    "\n",
    "This script is used to calculate the homotopic meta-connectivity in four groups, SNC, NC, MCI, AD\n",
    "\"\"\"\n",
    "\n",
    "# brain region labels for your reference\n",
    "regions = ['aCNG-L', 'aCNG-R','mCNG-L','mCNG-R','pCNG-L','pCNG-R', 'HIP-L','HIP-R','PHG-L','PHG-R','AMY-L','AMY-R', 'sTEMp-L','sTEMP-R','mTEMp-L','mTEMp-R']\n",
    "regionswithgroups = ['groups','aCNG-L', 'aCNG-R','mCNG-L','mCNG-R','pCNG-L','pCNG-R', 'HIP-L','HIP-R','PHG-L','PHG-R','AMY-L','AMY-R', 'sTEMp-L','sTEMP-R','mTEMp-L','mTEMp-R']\n",
    "group = ['SNC', 'NC', 'MCI','AD']\n",
    "regionsHalf = np.array(['aCNG', 'mCNG','pCNG','HIP','PHG','AMY','sTEMp', 'mTEMp'])\n",
    "\n",
    "regions14 = []\n",
    "for i in range(14):\n",
    "    wt = [\"regions_\", str(i)]\n",
    "    wt = \"\".join(wt)\n",
    "    regions14.append(wt)\n",
    "\n",
    "# iterate simulated functional connectivity\n",
    "if __name__ == \"__main__\":\n",
    "    Trimer_Homo = pd.DataFrame(columns=['groups','trimer_homo','aCNG','mCNG','pCNG','HIP','PHG','AMY','sTEMp','mTEMp' ])\n",
    "    Trimer_Hetero  = pd.DataFrame(columns=['groups','trimer_hetero','aCNG','mCNG','pCNG','HIP','PHG','AMY','sTEMp','mTEMp' ])\n",
    "    Trimer = pd.DataFrame()\n",
    "    tmp_col = [\"group\", \"caseid\"]\n",
    "    tmp_col.extend(regionsHalf)\n",
    "    for grp in group:\n",
    "        # subject case ids\n",
    "        ldir = os.listdir(\"/home/yat-lok/workspace/data4project/lateralization/ts_fmri/\"+ grp+'-TS')\n",
    "        # ldir = os.listdir('/home/wayne/TS-4-Vik/'+grp+'-TS/')\n",
    "        tmp_homo = np.array([])\n",
    "        homoRegions = np.ones((1,len(regionsHalf)))\n",
    "        for ind, y in enumerate(ldir):\n",
    "            # import empirical functional connectivity\n",
    "            # Here is the path of the mat file of the FC data\n",
    "            pth_efc = \"/home/yat-lok/workspace/data4project/lateralization/ts_fmri/\"+ grp+'-TS/'+ y +\"/ROISignals_\"+ y +\".mat\"\n",
    "            # pth_efc = \"/home/wayne/TS-4-Vik/\"+grp+\"-TS/\"+ y +\"/ROISignals_\"+ y +\".mat\"\n",
    "            ea = scipy.io.loadmat(pth_efc)\n",
    "            all = ea['ROISignals']\n",
    "            df = pd.DataFrame.from_dict(all)\n",
    "            df.columns = regions\n",
    "            # calculate the meta-connectivity, using existing script:\n",
    "            dFCstream = TS2dFCstream(df.to_numpy(), 5, None, '2D')\n",
    "            # Calculate MC\n",
    "            MC_MC = dFCstream2MC(dFCstream)\n",
    "            # Calculate Trimers results, with nxnxn information\n",
    "            MC_case = dFCstream2Trimers(dFCstream)\n",
    "            region_homo_value = [grp, y]\n",
    "            for i in range(0,15,2):\n",
    "                ij_list = []\n",
    "                j = i+1\n",
    "                new_list = list(range(16))\n",
    "                del new_list[i:j+1]\n",
    "                # iterate the homo connectivity values\n",
    "                for ai in new_list:\n",
    "                    homo_value = MC_case[i,j,ai]\n",
    "                    ij_list.append(homo_value)\n",
    "                mean_value = np.mean(ij_list)\n",
    "                region_homo_value.append(mean_value)\n",
    "            single_homo = pd.DataFrame([region_homo_value], columns= tmp_col)\n",
    "            Trimer = pd.concat([Trimer, single_homo], axis = 0, ignore_index=True)\n",
    "    print(Trimer)\n",
    "\n",
    "        # MC_homo = np.mean(MC_all, 3)\n",
    "        # MC_single_groups = np.zeros((14, 8))\n",
    "        # # only pick up L sides of the regions\n",
    "        # for idnx, i in enumerate(range(0,15,2)):\n",
    "        #     j = i+1 # represent R side\n",
    "        #     newList = list(range(16))\n",
    "        #     del newList[i:j+1] # drop the target regions L and R\n",
    "        #     for idx, restNode in enumerate(newList):\n",
    "        #         MC_single_groups[idx,idnx] = MC_homo[i,j,restNode] # In rest of the 14 regions, iternate the third dimensions, and pick up the homotopic MC\n",
    "        # MC_single = pd.DataFrame(MC_single_groups, index=regions14, columns=regionsHalf)\n",
    "        # grpInfo = [grp] * 14\n",
    "        # MC_single.insert(0, \"group\", grpInfo)\n",
    "        # Trimer = Trimer.append(MC_single)\n",
    "    # Trimer.to_excel(\"/mnt/c/Users/Wayne/tvb/gc1sec_res/mc_homo.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "participation coefficient MC\n",
    "\n",
    "step1: generate MC for all cases\n",
    "\n",
    "step2: sort MC to djouya order\n",
    "\n",
    "step3: calculate participation_coef_sign for everyone\n",
    "\n",
    "step4: average value within cluster\n",
    "\n",
    "step5: have the final table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21546/2293393608.py:15: DeprecationWarning: Please use `pearsonr` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  from scipy.stats.stats import pearsonr\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "from turtle import color\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/home/yat-lok/workspace/Network-science-Toolbox/Python')\n",
    "# sys.path.append('/home/wayne/github/TVB_workflow/new_g_optimal')\n",
    "# sys.path.append('/home/wayne/github/Network-science-Toolbox/Python')\n",
    "from TS2dFCstream import TS2dFCstream\n",
    "from dFCstream2Trimers import dFCstream2Trimers\n",
    "from dFCstream2MC import dFCstream2MC\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats.stats import pearsonr\n",
    "import itertools\n",
    "import os\n",
    "import scipy.io\n",
    "\n",
    "# label = '/mnt/c/Users/Wayne/tvb/gc1sec_res/meta/Region_Labels_90ROIs.txt'\n",
    "# list_ = open(label).read().split()\n",
    "# region = list_[1::2]\n",
    "\n",
    "regions = ['aCNG-L', 'aCNG-R','mCNG-L','mCNG-R','pCNG-L','pCNG-R', 'HIP-L','HIP-R','PHG-L','PHG-R','AMY-L','AMY-R', 'sTEMp-L','sTEMP-R','mTEMp-L','mTEMp-R']\n",
    "group = ['SNC', 'NC', 'MCI','AD']\n",
    "# path = '/mnt/c/Users/Wayne/tvb/stat_data/Gc_Go.xlsx'\n",
    "\n",
    "# combination set\n",
    "comba = list(itertools.combinations(range(len(regions)), 2))\n",
    "# give labels to comba\n",
    "comba_with_name = []\n",
    "for x in comba:\n",
    "    tmp_one = (regions[x[0]], regions[x[1]])\n",
    "    comba_with_name.append(tmp_one)\n",
    "\n",
    "\n",
    "path = '/home/yat-lok/workspace/data4project/lateralization/tvb_parameters.xlsx'\n",
    "coData = pd.read_excel(path, index_col=0)\n",
    "\n",
    "djouya_index = scipy.io.loadmat('/home/yat-lok/workspace/data4project/lateralization/gc1sec_res/meta/idx.mat')\n",
    "mc_index = djouya_index['idx'].T[0] -1\n",
    "\n",
    "module_ci = []\n",
    "for i in range(120):\n",
    "    if i < 20:\n",
    "        module_ci.append(1)\n",
    "    elif i >=20 and i < 40:\n",
    "        module_ci.append(2)\n",
    "    elif i >=40 and i < 60:\n",
    "        module_ci.append(3)\n",
    "    elif i >= 60 and i < 75:\n",
    "        module_ci.append(4)\n",
    "    else:\n",
    "        module_ci.append(5)\n",
    "\n",
    "\n",
    "edge_num = int((len(regions)*(len(regions)-1)) / 2)\n",
    "mc_all = np.zeros((edge_num,edge_num, len(coData.index)))\n",
    "for id, grp in enumerate(group):\n",
    "    mc_subject = np.zeros((edge_num,edge_num, len(coData.index[coData.groups == grp])))\n",
    "    for ind, y in enumerate(coData.index[coData.groups == grp]):\n",
    "        # import empirical functional connectivity\n",
    "        # Here is the path of the mat file of the FC data\n",
    "        # ldir = \"/mnt/c/Users/Wayne/tvb/TS-4-Vik/\"+ grp+'-TS/'+ y +\"/ROISignals_\"+ y +\".mat\"\n",
    "        ldir = \"/home/yat-lok/workspace/data4project/lateralization/ts_fmri/\"+ grp+'-TS/'+ y +\"/ROISignals_\"+ y +\".mat\"\n",
    "        ea = scipy.io.loadmat(ldir)\n",
    "        all = ea['ROISignals']\n",
    "        df = pd.DataFrame.from_dict(all)\n",
    "        df.columns = regions\n",
    "        dFCstream = TS2dFCstream(df.to_numpy(), 5, None, '2D')\n",
    "        _mc = dFCstream2MC(dFCstream)\n",
    "        # sort the matrix\n",
    "        mc_single = np.zeros((len(mc_index),len(mc_index)))\n",
    "        for mc_row in range(len(mc_index)-1):\n",
    "            for mc_col in range(mc_row+1,len(mc_index)):\n",
    "                mc_single[mc_row, mc_col] = _mc[mc_index[mc_row], mc_index[mc_col]]\n",
    "        mc_sorted_single = mc_single + mc_single.T\n",
    "        # ci, Q = community_louvain(mc_sorted_single, gamma=1.1, ci=module_ci, B='negative_asym', seed=None)\n",
    "        # pos,_ = participation_coef_sign(mc_sorted_single, module_ci)\n",
    "        # mc_single = np.zeros((len(mc_index),len(mc_index)))\n",
    "        # for mc_row in range(len(mc_index)-1):\n",
    "        #     for mc_col in range(mc_row+1,len(mc_index)):\n",
    "        #         mc_single[mc_row, mc_col] = _mc[ci[mc_row], ci[mc_col]]\n",
    "        # mc_sorted_single = mc_single + mc_single.T\n",
    "        # Calculate MC & write to matrix\n",
    "        mc_subject[:,:,ind] = mc_sorted_single\n",
    "    mc_all[:,:,id] = np.mean(mc_subject, axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.67821145 0.57718953 0.63624063 0.70218381 0.41954568]]\n",
      "[[0.54889275 0.60860135 0.40227524 0.67007567 0.31811624]]\n",
      "[[0.70647981 0.74810775 0.7109093  0.7023592  0.58473956]]\n",
      "[[0.65737997 0.68948706 0.69297586 0.70479571 0.52346244]]\n",
      "[[0.59247631 0.58093187 0.5600228  0.64368419 0.45780825]]\n",
      "[[0.53430047 0.5946995  0.54598423 0.66712916 0.50011721]]\n",
      "[[0.73415903 0.75698641 0.71395664 0.73851384 0.63580614]]\n",
      "[[0.73851823 0.74457986 0.74555803 0.7310649  0.50750289]]\n",
      "[[0.69922563 0.74654754 0.67641748 0.71559375 0.63752197]]\n",
      "[[0.61601671 0.60853323 0.5804344  0.55948142 0.2753628 ]]\n",
      "[[0.65591949 0.72519201 0.71997449 0.72328293 0.49771847]]\n",
      "[[0.57868484 0.63542439 0.66690471 0.71832976 0.51750177]]\n",
      "[[0.72254455 0.72478316 0.70113363 0.69619454 0.50813183]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 13 is out of bounds for axis 2 with size 13",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/yat-lok/workspace/tvbtools/application/meta-connectivity.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yat-lok/workspace/tvbtools/application/meta-connectivity.ipynb#X20sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m overall_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yat-lok/workspace/tvbtools/application/meta-connectivity.ipynb#X20sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mfor\u001b[39;00m ind \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(coData\u001b[39m.\u001b[39mindex)):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/yat-lok/workspace/tvbtools/application/meta-connectivity.ipynb#X20sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     mat \u001b[39m=\u001b[39m mat_preprocessing(mc_subject, ind, labels\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49marray(comba_with_name)[mc_index])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yat-lok/workspace/tvbtools/application/meta-connectivity.ipynb#X20sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39m#ci, Q = community_louvain(mat.to_numpy(), ci=module_ci, gamma = 1.5, B='negative_asym', seed=None)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yat-lok/workspace/tvbtools/application/meta-connectivity.ipynb#X20sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39m# fisrt method:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yat-lok/workspace/tvbtools/application/meta-connectivity.ipynb#X20sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     pos,_ \u001b[39m=\u001b[39m participation_coef_sign(mat\u001b[39m.\u001b[39mto_numpy(), module_ci)\n",
      "\u001b[1;32m/home/yat-lok/workspace/tvbtools/application/meta-connectivity.ipynb Cell 15\u001b[0m in \u001b[0;36mmat_preprocessing\u001b[0;34m(mat, caseid_index, labels)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yat-lok/workspace/tvbtools/application/meta-connectivity.ipynb#X20sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmat_preprocessing\u001b[39m(mat, caseid_index, labels):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/yat-lok/workspace/tvbtools/application/meta-connectivity.ipynb#X20sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     mat \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(mat[:,:,caseid_index], columns\u001b[39m=\u001b[39mlabels, index\u001b[39m=\u001b[39mlabels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yat-lok/workspace/tvbtools/application/meta-connectivity.ipynb#X20sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m mat\n",
      "\u001b[0;31mIndexError\u001b[0m: index 13 is out of bounds for axis 2 with size 13"
     ]
    }
   ],
   "source": [
    "# calculate the cluster\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import os\n",
    "import pandas as pd\n",
    "from bct.algorithms import community_louvain\n",
    "from bct.algorithms.centrality import participation_coef_sign\n",
    "\n",
    "group = ['SNC', 'NC', 'MCI','AD']\n",
    "regions = ['aCNG-L', 'aCNG-R','mCNG-L','mCNG-R','pCNG-L','pCNG-R', 'HIP-L','HIP-R','PHG-L','PHG-R','AMY-L','AMY-R', 'sTEMp-L','sTEMP-R','mTEMp-L','mTEMp-R']\n",
    "node_dict = {0:'aCNG-L', 1:'aCNG-R',2: 'mCNG-L',3:'mCNG-R',4:'pCNG-L',5:'pCNG-R', 6:'HIP-L',7:'HIP-R',8:'PHG-L',9:'PHG-R',10:'AMY-L',11:'AMY-R', 12:'sTEMp-L',13:'sTEMp-R',14:'mTEMp-L',15:'mTEMp-R'}\n",
    "\n",
    "\n",
    "\n",
    "def mat_preprocessing(mat, caseid_index, labels):\n",
    "    mat = pd.DataFrame(mat[:,:,caseid_index], columns=labels, index=labels)\n",
    "    return mat\n",
    "\n",
    "\n",
    "overall_df = pd.DataFrame()\n",
    "for ind in range(len(coData.index)):\n",
    "    mat = mat_preprocessing(mc_subject, ind, labels=np.array(comba_with_name)[mc_index])\n",
    "    #ci, Q = community_louvain(mat.to_numpy(), ci=module_ci, gamma = 1.5, B='negative_asym', seed=None)\n",
    "    # fisrt method:\n",
    "    pos,_ = participation_coef_sign(mat.to_numpy(), module_ci)\n",
    "    module_df = pd.DataFrame(module_ci, columns = [\"cluster\"])\n",
    "    pos_df = pd.DataFrame(pos, columns = [\"part_coef\"])\n",
    "    single_part = pd.concat([module_df, pos_df], axis=1, ignore_index=True)\n",
    "    single_part.columns = [\"cluster\", \"part_coef\"]\n",
    "    print(single_part.groupby(\"cluster\").mean().to_numpy().T)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     ci_name_list = [\"cluster_\" + str(i) for i in module_ci]\n",
    "#     cluster_info = pd.DataFrame(ci_name_list)\n",
    "#     cluster_info.columns = [\"cluster\"]\n",
    "#     part_coe = pd.DataFrame(pos)\n",
    "#     part_coe.columns = [\"participation_coef\"]\n",
    "#     grp_info = pd.Series([group[ind]])\n",
    "#     grp_col = grp_info.repeat(len(mat.index))\n",
    "#     grp_col = grp_col.reset_index(drop=True)\n",
    "#     _tmp = pd.concat([grp_col, part_coe, cluster_info],axis=1, ignore_index=True)\n",
    "#     overall_df = pd.concat([overall_df, _tmp], ignore_index=True)\n",
    "# overall_df.columns = [\"group\",\"participation_coef\", \"cluster\"]\n",
    "# overall_df.to_excel(\"/home/yat-lok/workspace/data4project/lateralization/gc1sec_res/meta/participation_coef.xlsx\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tvbenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d6eff59d82162ad618c2fda16bbe4a2b1e156e75fbd6961cfe85de3ca5351f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
