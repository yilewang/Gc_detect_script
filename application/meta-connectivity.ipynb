{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to do meta-connectivity in two parts. First part: Homotopic connectivity analysis. Second part: cluster analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The homotopic connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "from turtle import color\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/mnt/c/Users/Wayne/tvb/Network-science-Toolbox/Python')\n",
    "# sys.path.append('/home/wayne/github/TVB_workflow/new_g_optimal')\n",
    "# sys.path.append('/home/wayne/github/Network-science-Toolbox/Python')\n",
    "from TS2dFCstream import TS2dFCstream\n",
    "from dFCstream2Trimers import dFCstream2Trimers\n",
    "from dFCstream2MC import dFCstream2MC\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats.stats import pearsonr\n",
    "import itertools\n",
    "import os\n",
    "import scipy.io\n",
    "\n",
    "plat4 = \"desktop\"\n",
    "\n",
    "\"\"\"\n",
    "@Author: Yile Wang\n",
    "\n",
    "This script is used to calculate the homotopic meta-connectivity in four groups, SNC, NC, MCI, AD\n",
    "\"\"\"\n",
    "\n",
    "# brain region labels for your reference\n",
    "regions = ['aCNG-L', 'aCNG-R','mCNG-L','mCNG-R','pCNG-L','pCNG-R', 'HIP-L','HIP-R','PHG-L','PHG-R','AMY-L','AMY-R', 'sTEMp-L','sTEMP-R','mTEMp-L','mTEMp-R']\n",
    "regionswithgroups = ['groups','aCNG-L', 'aCNG-R','mCNG-L','mCNG-R','pCNG-L','pCNG-R', 'HIP-L','HIP-R','PHG-L','PHG-R','AMY-L','AMY-R', 'sTEMp-L','sTEMP-R','mTEMp-L','mTEMp-R']\n",
    "group = ['SNC', 'NC', 'MCI','AD']\n",
    "regionsHalf = np.array(['aCNG', 'mCNG','pCNG','HIP','PHG','AMY','sTEMp', 'mTEMp'])\n",
    "\n",
    "regions14 = []\n",
    "for i in range(14):\n",
    "    wt = [\"regions_\", str(i)]\n",
    "    wt = \"\".join(wt)\n",
    "    regions14.append(wt)\n",
    "\n",
    "# iterate simulated functional connectivity\n",
    "if __name__ == \"__main__\":\n",
    "    Trimer_Homo = pd.DataFrame(columns=['groups','trimer_homo','aCNG','mCNG','pCNG','HIP','PHG','AMY','sTEMp','mTEMp' ])\n",
    "    Trimer_Hetero  = pd.DataFrame(columns=['groups','trimer_hetero','aCNG','mCNG','pCNG','HIP','PHG','AMY','sTEMp','mTEMp' ])\n",
    "    Trimer = pd.DataFrame()\n",
    "    \n",
    "    for grp in group:\n",
    "        # subject case ids\n",
    "        if plat4 == \"desktop\":\n",
    "            ldir = os.listdir(\"/mnt/c/Users/Wayne/tvb/TS-4-Vik/\"+ grp+'-TS')\n",
    "        elif plat4 == \"laptop\":\n",
    "            ldir = os.listdir(\"/home/yat-lok/workspace/data4project/lateralization/ts_fmri/\"+ grp+'-TS')\n",
    "        # ldir = os.listdir('/home/wayne/TS-4-Vik/'+grp+'-TS/')\n",
    "        MC_all = np.zeros((16,16, 16, len(ldir)))\n",
    "        tmp_homo = np.array([])\n",
    "        homoRegions = np.ones((1,len(regionsHalf)))\n",
    "        for ind, y in enumerate(ldir):\n",
    "            # import empirical functional connectivity\n",
    "            # Here is the path of the mat file of the FC data\n",
    "            if plat4 == \"desktop\":\n",
    "                pth_efc = \"/mnt/c/Users/Wayne/tvb/TS-4-Vik/\"+ grp+'-TS/'+ y +\"/ROISignals_\"+ y +\".mat\"\n",
    "            elif plat4 == \"laptop\":\n",
    "                pth_efc = \"/home/yat-lok/workspace/data4project/lateralization/ts_fmri/\"+ grp+'-TS/'+ y +\"/ROISignals_\"+ y +\".mat\"\n",
    "            # pth_efc = \"/home/wayne/TS-4-Vik/\"+grp+\"-TS/\"+ y +\"/ROISignals_\"+ y +\".mat\"\n",
    "            ea = scipy.io.loadmat(pth_efc)\n",
    "            all = ea['ROISignals']\n",
    "            df = pd.DataFrame.from_dict(all)\n",
    "            df.columns = regions\n",
    "            # calculate the meta-connectivity, using existing script:\n",
    "            dFCstream = TS2dFCstream(df.to_numpy(), 5, None, '2D')\n",
    "            # Calculate MC\n",
    "            MC_MC = dFCstream2MC(dFCstream)\n",
    "            # Calculate Trimers results, with nxnxn information\n",
    "            MC_all[:,:,:,ind] = dFCstream2Trimers(dFCstream)\n",
    "        MC_homo = np.mean(MC_all, 3)\n",
    "        MC_single_groups = np.zeros((14, 8))\n",
    "        # only pick up L sides of the regions\n",
    "        for idnx, i in enumerate(range(0,15,2)):\n",
    "            j = i+1 # represent R side\n",
    "            newList = list(range(16))\n",
    "            del newList[i:j+1] # drop the target regions L and R\n",
    "            for idx, restNode in enumerate(newList):\n",
    "                MC_single_groups[idx,idnx] = MC_homo[i,j,restNode] # In rest of the 14 regions, iternate the third dimensions, and pick up the homotopic MC\n",
    "        MC_single = pd.DataFrame(MC_single_groups, index=regions14, columns=regionsHalf)\n",
    "        grpInfo = [grp] * 14\n",
    "        MC_single.insert(0, \"group\", grpInfo)\n",
    "        Trimer = Trimer.append(MC_single)\n",
    "    # Trimer.to_excel(\"/mnt/c/Users/Wayne/tvb/gc1sec_res/mc_homo.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 1, data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "from turtle import color\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/home/yat-lok/workspace/Network-science-Toolbox/Python')\n",
    "# sys.path.append('/home/wayne/github/TVB_workflow/new_g_optimal')\n",
    "# sys.path.append('/home/wayne/github/Network-science-Toolbox/Python')\n",
    "from TS2dFCstream import TS2dFCstream\n",
    "from dFCstream2Trimers import dFCstream2Trimers\n",
    "from dFCstream2MC import dFCstream2MC\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats.stats import pearsonr\n",
    "import itertools\n",
    "import os\n",
    "import scipy.io\n",
    "\n",
    "# label = '/mnt/c/Users/Wayne/tvb/gc1sec_res/meta/Region_Labels_90ROIs.txt'\n",
    "# list_ = open(label).read().split()\n",
    "# region = list_[1::2]\n",
    "\n",
    "regions = ['aCNG-L', 'aCNG-R','mCNG-L','mCNG-R','pCNG-L','pCNG-R', 'HIP-L','HIP-R','PHG-L','PHG-R','AMY-L','AMY-R', 'sTEMp-L','sTEMP-R','mTEMp-L','mTEMp-R']\n",
    "group = ['SNC', 'NC', 'MCI','AD']\n",
    "# path = '/mnt/c/Users/Wayne/tvb/stat_data/Gc_Go.xlsx'\n",
    "\n",
    "# combination set\n",
    "comba = list(itertools.combinations(range(len(regions)), 2))\n",
    "# give labels to comba\n",
    "comba_with_name = []\n",
    "for x in comba:\n",
    "    tmp_one = (regions[x[0]], regions[x[1]])\n",
    "    comba_with_name.append(tmp_one)\n",
    "\n",
    "\n",
    "path = '/home/yat-lok/workspace/data4project/lateralization/tvb_parameters.xlsx'\n",
    "coData = pd.read_excel(path, index_col=0)\n",
    "\n",
    "djouya_index = scipy.io.loadmat('/home/yat-lok/workspace/data4project/lateralization/gc1sec_res/meta/idx.mat')\n",
    "mc_index = djouya_index['idx'].T[0] -1\n",
    "\n",
    "module_ci = []\n",
    "for i in range(120):\n",
    "    if i < 20:\n",
    "        module_ci.append(1)\n",
    "    elif i >=20 and i < 40:\n",
    "        module_ci.append(2)\n",
    "    elif i >=40 and i < 60:\n",
    "        module_ci.append(3)\n",
    "    elif i >= 60 and i < 75:\n",
    "        module_ci.append(4)\n",
    "    else:\n",
    "        module_ci.append(5)\n",
    "\n",
    "\n",
    "edge_num = int((len(regions)*(len(regions)-1)) / 2)\n",
    "mc_all = np.zeros((edge_num,edge_num, len(group)))\n",
    "for id, grp in enumerate(group):\n",
    "    mc_subject = np.zeros((edge_num,edge_num, len(coData.index[coData.groups == grp])))\n",
    "    for ind, y in enumerate(coData.index[coData.groups == grp]):\n",
    "        # import empirical functional connectivity\n",
    "        # Here is the path of the mat file of the FC data\n",
    "        # ldir = \"/mnt/c/Users/Wayne/tvb/TS-4-Vik/\"+ grp+'-TS/'+ y +\"/ROISignals_\"+ y +\".mat\"\n",
    "        ldir = \"/home/yat-lok/workspace/data4project/lateralization/ts_fmri/\"+ grp+'-TS/'+ y +\"/ROISignals_\"+ y +\".mat\"\n",
    "        ea = scipy.io.loadmat(ldir)\n",
    "        all = ea['ROISignals']\n",
    "        df = pd.DataFrame.from_dict(all)\n",
    "        df.columns = regions\n",
    "        dFCstream = TS2dFCstream(df.to_numpy(), 5, None, '2D')\n",
    "        _mc = dFCstream2MC(dFCstream)\n",
    "        # sort the matrix\n",
    "        mc_single = np.zeros((len(mc_index),len(mc_index)))\n",
    "        for mc_row in range(len(mc_index)-1):\n",
    "            for mc_col in range(mc_row+1,len(mc_index)):\n",
    "                mc_single[mc_row, mc_col] = _mc[mc_index[mc_row], mc_index[mc_col]]\n",
    "        mc_sorted_single = mc_single + mc_single.T\n",
    "        # ci, Q = community_louvain(mc_sorted_single, gamma=1.1, ci=module_ci, B='negative_asym', seed=None)\n",
    "        # pos,_ = participation_coef_sign(mc_sorted_single, module_ci)\n",
    "        # mc_single = np.zeros((len(mc_index),len(mc_index)))\n",
    "        # for mc_row in range(len(mc_index)-1):\n",
    "        #     for mc_col in range(mc_row+1,len(mc_index)):\n",
    "        #         mc_single[mc_row, mc_col] = _mc[ci[mc_row], ci[mc_col]]\n",
    "        # mc_sorted_single = mc_single + mc_single.T\n",
    "        # Calculate MC & write to matrix\n",
    "        mc_subject[:,:,ind] = mc_sorted_single\n",
    "    mc_all[:,:,id] = np.mean(mc_subject, axis=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 2, louvain algorithm for community check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the cluster\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import os\n",
    "import pandas as pd\n",
    "from bct.algorithms import community_louvain\n",
    "from bct.algorithms.centrality import participation_coef_sign\n",
    "\n",
    "group = ['SNC', 'NC', 'MCI','AD']\n",
    "regions = ['aCNG-L', 'aCNG-R','mCNG-L','mCNG-R','pCNG-L','pCNG-R', 'HIP-L','HIP-R','PHG-L','PHG-R','AMY-L','AMY-R', 'sTEMp-L','sTEMP-R','mTEMp-L','mTEMp-R']\n",
    "node_dict = {0:'aCNG-L', 1:'aCNG-R',2: 'mCNG-L',3:'mCNG-R',4:'pCNG-L',5:'pCNG-R', 6:'HIP-L',7:'HIP-R',8:'PHG-L',9:'PHG-R',10:'AMY-L',11:'AMY-R', 12:'sTEMp-L',13:'sTEMp-R',14:'mTEMp-L',15:'mTEMp-R'}\n",
    "\n",
    "\n",
    "\n",
    "def mat_preprocessing(mat, group_index, labels):\n",
    "    mat = pd.DataFrame(mat[:,:,group_index], columns=labels, index=labels)\n",
    "    return mat\n",
    "\n",
    "\n",
    "overall_df = pd.DataFrame()\n",
    "for ind in range(len(group)):\n",
    "    mat = mat_preprocessing(mc_all, ind, labels=np.array(comba_with_name)[mc_index])\n",
    "    ci, Q = community_louvain(mat.to_numpy(), ci=module_ci, gamma = 1.5, B='negative_asym', seed=None)\n",
    "    # fisrt method:\n",
    "    pos,_ = participation_coef_sign(mat.to_numpy(), module_ci)\n",
    "    ci_name_list = [\"cluster_\" + str(i) for i in module_ci]\n",
    "    cluster_info = pd.DataFrame(ci_name_list)\n",
    "    cluster_info.columns = [\"cluster\"]\n",
    "    part_coe = pd.DataFrame(pos)\n",
    "    part_coe.columns = [\"participation_coef\"]\n",
    "    grp_info = pd.Series([group[ind]])\n",
    "    grp_col = grp_info.repeat(len(mat.index))\n",
    "    grp_col = grp_col.reset_index(drop=True)\n",
    "    _tmp = pd.concat([grp_col, part_coe, cluster_info],axis=1, ignore_index=True)\n",
    "    overall_df = pd.concat([overall_df, _tmp], ignore_index=True)\n",
    "overall_df.columns = [\"group\",\"participation_coef\", \"cluster\"]\n",
    "overall_df.to_excel(\"/home/yat-lok/workspace/data4project/lateralization/gc1sec_res/meta/participation_coef.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def links_single_module(ci, cluster_index):\n",
    "#     #bctpy\n",
    "#     links_within_m = [item for item in np.where(ci==cluster_index)[0]]\n",
    "#     return links_within_m\n",
    "\n",
    "# def participation_coef_single_cluster(mat, links_within_m):\n",
    "#     participation_coef_single = []\n",
    "#     for i in range(len(links_within_m)):\n",
    "#         drop_links_within = [ele for ele in links_within_m if ele not in [i]]\n",
    "#         drop_links_outside = [ele for ele in range(len(mat.index)) if ele not in [i]]\n",
    "#         n_l = np.sum(mat.iloc[drop_links_outside, links_within_m[i]])\n",
    "#         single_link = []\n",
    "#         for j in range(len(drop_links_within)):\n",
    "#             n_l_within_m = np.sum(mat.iloc[drop_links_within[j], links_within_m[i]])\n",
    "#             _value = (n_l_within_m/n_l)**2\n",
    "#             single_link.append(_value)\n",
    "#         pl=1 - np.sum(single_link)\n",
    "#         participation_coef_single.append(pl)\n",
    "#     return participation_coef_single\n",
    "\n",
    "# second method:\n",
    "#     single_grp_all_clusters = {}\n",
    "#     for cii in range(1,max(ci)+1):\n",
    "#         links_within_m = links_single_module(ci, cii)\n",
    "#         participation_coef_single = participation_coef_single_cluster(mat, links_within_m)\n",
    "#         str_name = \"cluster_\"+str(cii)\n",
    "#         single_grp_all_clusters[str_name] = participation_coef_single\n",
    "#     keys_list = list(single_grp_all_clusters.keys())\n",
    "\n",
    "\n",
    "#     all_clusters_df = pd.DataFrame()\n",
    "#     for ii in range(len(keys_list)):\n",
    "#         _tmp = pd.DataFrame({keys_list[ii]:single_grp_all_clusters[keys_list[ii]]})\n",
    "#         _tmp.columns = [\"participation_coef\"]\n",
    "#         cluster_info = pd.Series([keys_list[ii]])\n",
    "#         cluster_col = cluster_info.repeat(len(_tmp))\n",
    "#         cluster_col = cluster_col.reset_index(drop=True)\n",
    "#         _tmp_grp = pd.concat([_tmp, cluster_col], axis=1, ignore_index=True)\n",
    "#         all_clusters_df = pd.concat([all_clusters_df,_tmp_grp], ignore_index=True)\n",
    "\n",
    "#     grp_info = pd.Series([group[ind]])\n",
    "#     grp_col = grp_info.repeat(len(mat.index))\n",
    "#     grp_col = grp_col.reset_index(drop=True)\n",
    "#     all_clusters_df = pd.concat([grp_col,all_clusters_df], axis=1, ignore_index=True)\n",
    "#     all_clusters_df.columns = [\"group\",\"participation_coef\", \"cluster\"]\n",
    "#     overall_df = pd.concat([overall_df, all_clusters_df], ignore_index=True)\n",
    "# overall_df.to_excel(\"/mnt/c/Users/Wayne/tvb/gc1sec_res/meta/participation_coef.xlsx\")\n",
    "\n",
    "\n",
    "# ### create edge network\n",
    "# G = nx.Graph()\n",
    "# G.add_edges_from(edge)\n",
    "\n",
    "# ### retrun partition as a dict\n",
    "# partition = community_louvain.best_partition(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ci, Q = community_louvain(mc_all[:,:,1], gamma=1.1, ci=module_ci, B='negative_asym', seed=None)\n",
    "# mc_plot=np.zeros((120,120))\n",
    "# for mc_row in range(120-1):\n",
    "#     for mc_col in range(mc_row+1,120):\n",
    "#         mc_plot[mc_row, mc_col] = mc_all[:,:,1][ci[mc_row], ci[mc_col]]\n",
    "# mc_sorted_single = mc_single + mc_single.T\n",
    "\n",
    "\n",
    "fig=plt.figure(figsize=(7,5), dpi=300)\n",
    "axes = fig.add_subplot(111)\n",
    "sns.heatmap(mc_all[:,:,1],cmap=\"crest_r\", ax=axes)\n",
    "axes.set_ylabel(\"edges\")\n",
    "axes.set_xlabel(\"edges\")\n",
    "axes.set_yticks(np.arange(0,121,20))\n",
    "axes.set_xticks(np.arange(0,121,20))\n",
    "axes.set_yticklabels(np.arange(0,121,20))\n",
    "axes.set_xticklabels(np.arange(0,121,20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An individualized method of meta-connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homotopic connectivity MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from turtle import color\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/home/yat-lok/workspace/Network-science-Toolbox/Python')\n",
    "# sys.path.append('/home/wayne/github/TVB_workflow/new_g_optimal')\n",
    "# sys.path.append('/home/wayne/github/Network-science-Toolbox/Python')\n",
    "from TS2dFCstream import TS2dFCstream\n",
    "from dFCstream2Trimers import dFCstream2Trimers\n",
    "from dFCstream2MC import dFCstream2MC\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats.stats import pearsonr\n",
    "import itertools\n",
    "import os\n",
    "import scipy.io\n",
    "\n",
    "\"\"\"\n",
    "@Author: Yile Wang\n",
    "\n",
    "This script is used to calculate the homotopic meta-connectivity in four groups, SNC, NC, MCI, AD\n",
    "\"\"\"\n",
    "\n",
    "# brain region labels for your reference\n",
    "regions = ['aCNG-L', 'aCNG-R','mCNG-L','mCNG-R','pCNG-L','pCNG-R', 'HIP-L','HIP-R','PHG-L','PHG-R','AMY-L','AMY-R', 'sTEMp-L','sTEMP-R','mTEMp-L','mTEMp-R']\n",
    "regionswithgroups = ['groups','aCNG-L', 'aCNG-R','mCNG-L','mCNG-R','pCNG-L','pCNG-R', 'HIP-L','HIP-R','PHG-L','PHG-R','AMY-L','AMY-R', 'sTEMp-L','sTEMP-R','mTEMp-L','mTEMp-R']\n",
    "group = ['SNC', 'NC', 'MCI','AD']\n",
    "regionsHalf = np.array(['aCNG', 'mCNG','pCNG','HIP','PHG','AMY','sTEMp', 'mTEMp'])\n",
    "\n",
    "regions14 = []\n",
    "for i in range(14):\n",
    "    wt = [\"regions_\", str(i)]\n",
    "    wt = \"\".join(wt)\n",
    "    regions14.append(wt)\n",
    "\n",
    "# iterate simulated functional connectivity\n",
    "if __name__ == \"__main__\":\n",
    "    Trimer_Homo = pd.DataFrame(columns=['groups','trimer_homo','aCNG','mCNG','pCNG','HIP','PHG','AMY','sTEMp','mTEMp' ])\n",
    "    Trimer_Hetero  = pd.DataFrame(columns=['groups','trimer_hetero','aCNG','mCNG','pCNG','HIP','PHG','AMY','sTEMp','mTEMp' ])\n",
    "    Trimer = pd.DataFrame()\n",
    "    tmp_col = [\"group\", \"caseid\"]\n",
    "    tmp_col.extend(regionsHalf)\n",
    "    for grp in group:\n",
    "        # subject case ids\n",
    "        ldir = os.listdir(\"/home/yat-lok/workspace/data4project/lateralization/ts_fmri/\"+ grp+'-TS')\n",
    "        # ldir = os.listdir('/home/wayne/TS-4-Vik/'+grp+'-TS/')\n",
    "        tmp_homo = np.array([])\n",
    "        homoRegions = np.ones((1,len(regionsHalf)))\n",
    "        for ind, y in enumerate(ldir):\n",
    "            # import empirical functional connectivity\n",
    "            # Here is the path of the mat file of the FC data\n",
    "            pth_efc = \"/home/yat-lok/workspace/data4project/lateralization/ts_fmri/\"+ grp+'-TS/'+ y +\"/ROISignals_\"+ y +\".mat\"\n",
    "            # pth_efc = \"/home/wayne/TS-4-Vik/\"+grp+\"-TS/\"+ y +\"/ROISignals_\"+ y +\".mat\"\n",
    "            ea = scipy.io.loadmat(pth_efc)\n",
    "            all = ea['ROISignals']\n",
    "            df = pd.DataFrame.from_dict(all)\n",
    "            df.columns = regions\n",
    "            # calculate the meta-connectivity, using existing script:\n",
    "            dFCstream = TS2dFCstream(df.to_numpy(), 5, None, '2D')\n",
    "            # Calculate MC\n",
    "            MC_MC = dFCstream2MC(dFCstream)\n",
    "            # Calculate Trimers results, with nxnxn information\n",
    "            MC_case = dFCstream2Trimers(dFCstream)\n",
    "            region_homo_value = [grp, y]\n",
    "            for i in range(0,15,2):\n",
    "                ij_list = []\n",
    "                j = i+1\n",
    "                new_list = list(range(16))\n",
    "                del new_list[i:j+1]\n",
    "                # iterate the homo connectivity values\n",
    "                for ai in new_list:\n",
    "                    homo_value = MC_case[i,j,ai]\n",
    "                    ij_list.append(homo_value)\n",
    "                mean_value = np.mean(ij_list)\n",
    "                region_homo_value.append(mean_value)\n",
    "            single_homo = pd.DataFrame([region_homo_value], columns= tmp_col)\n",
    "            Trimer = pd.concat([Trimer, single_homo], axis = 0, ignore_index=True)\n",
    "    print(Trimer)\n",
    "\n",
    "        # MC_homo = np.mean(MC_all, 3)\n",
    "        # MC_single_groups = np.zeros((14, 8))\n",
    "        # # only pick up L sides of the regions\n",
    "        # for idnx, i in enumerate(range(0,15,2)):\n",
    "        #     j = i+1 # represent R side\n",
    "        #     newList = list(range(16))\n",
    "        #     del newList[i:j+1] # drop the target regions L and R\n",
    "        #     for idx, restNode in enumerate(newList):\n",
    "        #         MC_single_groups[idx,idnx] = MC_homo[i,j,restNode] # In rest of the 14 regions, iternate the third dimensions, and pick up the homotopic MC\n",
    "        # MC_single = pd.DataFrame(MC_single_groups, index=regions14, columns=regionsHalf)\n",
    "        # grpInfo = [grp] * 14\n",
    "        # MC_single.insert(0, \"group\", grpInfo)\n",
    "        # Trimer = Trimer.append(MC_single)\n",
    "    # Trimer.to_excel(\"/mnt/c/Users/Wayne/tvb/gc1sec_res/mc_homo.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "participation coefficient MC\n",
    "\n",
    "step1: generate MC for all cases\n",
    "\n",
    "step2: sort MC to djouya order\n",
    "\n",
    "step3: calculate participation_coef_sign for everyone\n",
    "\n",
    "step4: average value within cluster\n",
    "\n",
    "step5: have the final table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "from turtle import color\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/home/yat-lok/workspace/Network-science-Toolbox/Python')\n",
    "# sys.path.append('/home/wayne/github/TVB_workflow/new_g_optimal')\n",
    "# sys.path.append('/home/wayne/github/Network-science-Toolbox/Python')\n",
    "from TS2dFCstream import TS2dFCstream\n",
    "from dFCstream2Trimers import dFCstream2Trimers\n",
    "from dFCstream2MC import dFCstream2MC\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats.stats import pearsonr\n",
    "import itertools\n",
    "import os\n",
    "import scipy.io\n",
    "\n",
    "# label = '/mnt/c/Users/Wayne/tvb/gc1sec_res/meta/Region_Labels_90ROIs.txt'\n",
    "# list_ = open(label).read().split()\n",
    "# region = list_[1::2]\n",
    "\n",
    "regions = ['aCNG-L', 'aCNG-R','mCNG-L','mCNG-R','pCNG-L','pCNG-R', 'HIP-L','HIP-R','PHG-L','PHG-R','AMY-L','AMY-R', 'sTEMp-L','sTEMP-R','mTEMp-L','mTEMp-R']\n",
    "group = ['SNC', 'NC', 'MCI','AD']\n",
    "# path = '/mnt/c/Users/Wayne/tvb/stat_data/Gc_Go.xlsx'\n",
    "\n",
    "# combination set\n",
    "comba = list(itertools.combinations(range(len(regions)), 2))\n",
    "# give labels to comba\n",
    "comba_with_name = []\n",
    "for x in comba:\n",
    "    tmp_one = (regions[x[0]], regions[x[1]])\n",
    "    comba_with_name.append(tmp_one)\n",
    "\n",
    "path = '/home/yat-lok/workspace/data4project/lateralization/tvb_parameters.xlsx'\n",
    "coData = pd.read_excel(path, index_col=0)\n",
    "\n",
    "djouya_index = scipy.io.loadmat('/home/yat-lok/workspace/data4project/lateralization/gc1sec_res/meta/idx.mat')\n",
    "mc_index = djouya_index['idx'].T[0] -1\n",
    "\n",
    "module_ci = []\n",
    "for i in range(120):\n",
    "    if i < 20:\n",
    "        module_ci.append(1)\n",
    "    elif i >=20 and i < 40:\n",
    "        module_ci.append(2)\n",
    "    elif i >=40 and i < 60:\n",
    "        module_ci.append(3)\n",
    "    elif i >= 60 and i < 75:\n",
    "        module_ci.append(4)\n",
    "    else:\n",
    "        module_ci.append(5)\n",
    "\n",
    "edge_num = int((len(regions)*(len(regions)-1)) / 2)\n",
    "mc_subject = np.zeros((edge_num,edge_num, len(coData.index)))\n",
    "\n",
    "for ind, (grp, y) in enumerate(zip(coData.groups, coData.index)):\n",
    "    # import empirical functional connectivity\n",
    "    # Here is the path of the mat file of the FC data\n",
    "    # ldir = \"/mnt/c/Users/Wayne/tvb/TS-4-Vik/\"+ grp+'-TS/'+ y +\"/ROISignals_\"+ y +\".mat\"\n",
    "    ldir = \"/home/yat-lok/workspace/data4project/lateralization/ts_fmri/\"+ grp+'-TS/'+ y +\"/ROISignals_\"+ y +\".mat\"\n",
    "    ea = scipy.io.loadmat(ldir)\n",
    "    all = ea['ROISignals']\n",
    "    df = pd.DataFrame.from_dict(all)\n",
    "    df.columns = regions\n",
    "    dFCstream = TS2dFCstream(df.to_numpy(), 5, None, '2D')\n",
    "    _mc = dFCstream2MC(dFCstream)\n",
    "    # sort the matrix\n",
    "    mc_single = np.zeros((len(mc_index),len(mc_index)))\n",
    "    for mc_row in range(len(mc_index)-1):\n",
    "        for mc_col in range(mc_row+1,len(mc_index)):\n",
    "            mc_single[mc_row, mc_col] = _mc[mc_index[mc_row], mc_index[mc_col]]\n",
    "    mc_sorted_single = mc_single + mc_single.T\n",
    "    # ci, Q = community_louvain(mc_sorted_single, gamma=1.1, ci=module_ci, B='negative_asym', seed=None)\n",
    "    # pos,_ = participation_coef_sign(mc_sorted_single, module_ci)\n",
    "    # mc_single = np.zeros((len(mc_index),len(mc_index)))\n",
    "    # for mc_row in range(len(mc_index)-1):\n",
    "    #     for mc_col in range(mc_row+1,len(mc_index)):\n",
    "    #         mc_single[mc_row, mc_col] = _mc[ci[mc_row], ci[mc_col]]\n",
    "    # mc_sorted_single = mc_single + mc_single.T\n",
    "    # Calculate MC & write to matrix\n",
    "    mc_subject[:,:,ind] = mc_sorted_single\n",
    "print(mc_subject)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.76242141 0.72823894 0.7390848  0.69688171 0.56997351]]\n",
      "[[0.55713584 0.52681188 0.58979792 0.52202739 0.2729923 ]]\n",
      "[[0.42690786 0.60186652 0.59984195 0.60060949 0.38931623]]\n",
      "[[0.70986529 0.75241722 0.71291428 0.73866026 0.66692385]]\n",
      "[[0.72635956 0.75106824 0.68935524 0.69748081 0.62898161]]\n",
      "[[0.74475474 0.72517063 0.72962008 0.71513455 0.48276066]]\n",
      "[[0.6734735  0.71880384 0.64635806 0.68402646 0.53633061]]\n",
      "[[0.6916584  0.76306957 0.72094118 0.72336521 0.54887949]]\n",
      "[[0.70705238 0.74528421 0.70201998 0.67013537 0.53301498]]\n",
      "[[0.63219895 0.59686164 0.65380933 0.71034858 0.53560045]]\n",
      "[[0.72843391 0.72479426 0.73082299 0.64176627 0.52023686]]\n",
      "[[0.67780228 0.74988282 0.68092261 0.69631367 0.49481546]]\n",
      "[[0.70313534 0.61548698 0.62864243 0.67110632 0.59341374]]\n",
      "[[0.73207332 0.75452589 0.73305562 0.74444982 0.59994404]]\n",
      "[[0.70652023 0.75259977 0.69515603 0.69764068 0.64357085]]\n",
      "[[0.65992219 0.72673717 0.69965947 0.68544689 0.44588379]]\n",
      "[[0.70730477 0.71221595 0.67219482 0.72772481 0.34661668]]\n",
      "[[0.57096231 0.62433165 0.61892717 0.65212073 0.53245623]]\n",
      "[[0.73544041 0.75344589 0.73428101 0.747876   0.66603048]]\n",
      "[[0.6448414  0.6281072  0.60619184 0.62883091 0.38506027]]\n",
      "[[0.56418387 0.67331991 0.65648188 0.62652695 0.3359512 ]]\n",
      "[[0.68292347 0.7309559  0.72042323 0.63515499 0.49673476]]\n",
      "[[0.65824622 0.69176379 0.68318244 0.71605651 0.4851789 ]]\n",
      "[[0.54210284 0.66982945 0.52267492 0.51634232 0.35365925]]\n",
      "[[0.74612597 0.75852928 0.74466037 0.70258538 0.5683135 ]]\n",
      "[[0.74217604 0.67583245 0.70281696 0.72579561 0.46046454]]\n",
      "[[0.74059841 0.73937835 0.71466071 0.76500248 0.57960186]]\n",
      "[[0.51024544 0.64355537 0.69450751 0.69455374 0.48990269]]\n",
      "[[0.54951317 0.53926193 0.60874869 0.56915063 0.29677193]]\n",
      "[[0.61736089 0.66093812 0.69328855 0.66589193 0.53324662]]\n",
      "[[0.57942142 0.5699473  0.45034124 0.58551399 0.37928941]]\n",
      "[[0.66389874 0.71242132 0.66282276 0.63025038 0.5454271 ]]\n",
      "[[0.67019924 0.70627339 0.6837587  0.71851164 0.55146118]]\n",
      "[[0.70929437 0.70933804 0.69983115 0.71153327 0.47660632]]\n",
      "[[0.70800349 0.69787475 0.66841789 0.75180857 0.53900349]]\n",
      "[[0.6063054  0.57963309 0.56614701 0.71284931 0.53571997]]\n",
      "[[0.75078674 0.71481914 0.73063979 0.73190283 0.53320902]]\n",
      "[[0.68087935 0.74111529 0.69303224 0.70649534 0.62021828]]\n",
      "[[0.63270085 0.72523841 0.66412953 0.6735377  0.4934373 ]]\n",
      "[[0.35076991 0.64122718 0.60591104 0.6113312  0.54642263]]\n",
      "[[0.66364291 0.68393173 0.69859824 0.71933791 0.51753695]]\n",
      "[[0.75351828 0.75823979 0.76407685 0.76332374 0.68062811]]\n",
      "[[0.56628976 0.69010822 0.69091745 0.62172113 0.49653898]]\n",
      "[[0.5598607  0.57673377 0.68099263 0.72090527 0.49306993]]\n",
      "[[0.68840831 0.70842644 0.67181243 0.65378141 0.48076796]]\n",
      "[[0.71972672 0.72384592 0.72149585 0.7356591  0.5249876 ]]\n",
      "[[0.67571589 0.70573615 0.71909053 0.73322199 0.56914982]]\n",
      "[[0.53822609 0.62074867 0.6496982  0.58283497 0.4215737 ]]\n",
      "[[0.73456079 0.71119162 0.71590057 0.74623524 0.58831254]]\n",
      "[[0.30857733 0.57854668 0.67445617 0.62371459 0.36136861]]\n",
      "[[0.60075269 0.66583256 0.59399832 0.59681247 0.45218815]]\n",
      "[[0.31285301 0.63668003 0.59989362 0.59119942 0.45712552]]\n",
      "[[0.55211295 0.69512538 0.63904856 0.69854316 0.55611363]]\n",
      "[[0.60463189 0.59714428 0.34402374 0.60523913 0.43060843]]\n",
      "[[0.71015134 0.72118735 0.71205419 0.7058878  0.44741048]]\n",
      "[[0.64210664 0.6569388  0.71325691 0.7181501  0.52917343]]\n",
      "[[0.57805397 0.69697031 0.65172692 0.65604176 0.47175825]]\n",
      "[[0.59911557 0.68444392 0.57592589 0.67242782 0.46533887]]\n",
      "[[0.674449   0.69030298 0.61091158 0.70702876 0.51577445]]\n",
      "[[0.69368491 0.736054   0.70940068 0.76129704 0.58545158]]\n",
      "[[0.64955866 0.70427045 0.70089331 0.74112163 0.5286295 ]]\n",
      "[[0.67821145 0.57718953 0.63624063 0.70218381 0.41954568]]\n",
      "[[0.54889275 0.60860135 0.40227524 0.67007567 0.31811624]]\n",
      "[[0.70647981 0.74810775 0.7109093  0.7023592  0.58473956]]\n",
      "[[0.65737997 0.68948706 0.69297586 0.70479571 0.52346244]]\n",
      "[[0.59247631 0.58093187 0.5600228  0.64368419 0.45780825]]\n",
      "[[0.53430047 0.5946995  0.54598423 0.66712916 0.50011721]]\n",
      "[[0.73415903 0.75698641 0.71395664 0.73851384 0.63580614]]\n",
      "[[0.73851823 0.74457986 0.74555803 0.7310649  0.50750289]]\n",
      "[[0.69922563 0.74654754 0.67641748 0.71559375 0.63752197]]\n",
      "[[0.61601671 0.60853323 0.5804344  0.55948142 0.2753628 ]]\n",
      "[[0.65591949 0.72519201 0.71997449 0.72328293 0.49771847]]\n",
      "[[0.57868484 0.63542439 0.66690471 0.71832976 0.51750177]]\n",
      "[[0.72254455 0.72478316 0.70113363 0.69619454 0.50813183]]\n"
     ]
    }
   ],
   "source": [
    "# calculate the cluster\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import os\n",
    "import pandas as pd\n",
    "from bct.algorithms import community_louvain\n",
    "from bct.algorithms.centrality import participation_coef_sign\n",
    "\n",
    "group = ['SNC', 'NC', 'MCI','AD']\n",
    "regions = ['aCNG-L', 'aCNG-R','mCNG-L','mCNG-R','pCNG-L','pCNG-R', 'HIP-L','HIP-R','PHG-L','PHG-R','AMY-L','AMY-R', 'sTEMp-L','sTEMP-R','mTEMp-L','mTEMp-R']\n",
    "node_dict = {0:'aCNG-L', 1:'aCNG-R',2: 'mCNG-L',3:'mCNG-R',4:'pCNG-L',5:'pCNG-R', 6:'HIP-L',7:'HIP-R',8:'PHG-L',9:'PHG-R',10:'AMY-L',11:'AMY-R', 12:'sTEMp-L',13:'sTEMp-R',14:'mTEMp-L',15:'mTEMp-R'}\n",
    "\n",
    "def mat_preprocessing(mat, caseid_index, labels):\n",
    "    mat = pd.DataFrame(mat[:,:,caseid_index], columns=labels, index=labels)\n",
    "    return mat\n",
    "\n",
    "overall_df = pd.DataFrame()\n",
    "for ind in range(len(coData.index)):\n",
    "    mat = mat_preprocessing(mc_subject, ind, labels=np.array(comba_with_name)[mc_index])\n",
    "    #ci, Q = community_louvain(mat.to_numpy(), ci=module_ci, gamma = 1.5, B='negative_asym', seed=None)\n",
    "    # fisrt method:\n",
    "    pos,_ = participation_coef_sign(mat.to_numpy(), module_ci)\n",
    "    module_df = pd.DataFrame(module_ci, columns = [\"cluster\"])\n",
    "    pos_df = pd.DataFrame(pos, columns = [\"part_coef\"])\n",
    "    single_part = pd.concat([module_df, pos_df], axis=1, ignore_index=True)\n",
    "    single_part.columns = [\"cluster\", \"part_coef\"]\n",
    "    print(single_part.groupby(\"cluster\").mean().to_numpy().T[0])\n",
    "\n",
    "\n",
    "#     ci_name_list = [\"cluster_\" + str(i) for i in module_ci]\n",
    "#     cluster_info = pd.DataFrame(ci_name_list)\n",
    "#     cluster_info.columns = [\"cluster\"]\n",
    "#     part_coe = pd.DataFrame(pos)\n",
    "#     part_coe.columns = [\"participation_coef\"]\n",
    "#     grp_info = pd.Series([group[ind]])\n",
    "#     grp_col = grp_info.repeat(len(mat.index))\n",
    "#     grp_col = grp_col.reset_index(drop=True)\n",
    "#     _tmp = pd.concat([grp_col, part_coe, cluster_info],axis=1, ignore_index=True)\n",
    "#     overall_df = pd.concat([overall_df, _tmp], ignore_index=True)\n",
    "# overall_df.columns = [\"group\",\"participation_coef\", \"cluster\"]\n",
    "# overall_df.to_excel(\"/home/yat-lok/workspace/data4project/lateralization/gc1sec_res/meta/participation_coef.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tvbenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3c26eedd07840027ff202a94d88c89e67a86d8b5dcd58f087e1d46a589dbbcf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
